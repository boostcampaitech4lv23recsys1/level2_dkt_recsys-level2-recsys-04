{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "path = '/opt/ml/input/data/'\n",
    "\n",
    "train = pd.read_csv(path + 'train_data.csv', parse_dates=[\"Timestamp\"])\n",
    "test = pd.read_csv(path + 'test_data.csv', parse_dates=[\"Timestamp\"])\n",
    "\n",
    "dat = pd.concat([train, test], axis = 0)\n",
    "dat = dat.sort_values(by = ['userID', 'Timestamp'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_train = dat[dat['answerCode'] >= 0]\n",
    "_test = dat[dat['answerCode'] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_86008/2300459396.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _train['train_valid'] = 0\n"
     ]
    }
   ],
   "source": [
    "# valid 제작하는 함수 새로 개편.\n",
    "# 예전 valid 제작 함수는 1분 걸렸는데 0.6초만에 끗~\n",
    "_train['train_valid'] = 0\n",
    "_train.loc[_train.drop_duplicates(subset='userID', keep = 'last').index, 'train_valid'] = -1\n",
    "_valid = _train[_train['train_valid'] == -1]\n",
    "_train = _train[_train['train_valid'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class elo():\n",
    "    def __init__(self):\n",
    "        self.item_parameters = None\n",
    "        self.student_parameters = None\n",
    "\n",
    "    def get_new_theta(self,is_good_answer, beta, left_asymptote, theta, nb_previous_answers):\n",
    "        return theta + self.learning_rate_theta(nb_previous_answers) * (\n",
    "            is_good_answer - self.probability_of_good_answer(theta, beta, left_asymptote)\n",
    "        )\n",
    "\n",
    "    def get_new_beta(self,is_good_answer, beta, left_asymptote, theta, nb_previous_answers):\n",
    "        return beta - self.learning_rate_beta(nb_previous_answers) * (\n",
    "            is_good_answer - self.probability_of_good_answer(theta, beta, left_asymptote)\n",
    "        )\n",
    "\n",
    "    def learning_rate_theta(self,nb_answers):\n",
    "        return max(0.3 / (1 + 0.01 * nb_answers), 0.04)\n",
    "\n",
    "    def learning_rate_beta(self,nb_answers):\n",
    "        return 1 / (1 + 0.05 * nb_answers)\n",
    "\n",
    "    def probability_of_good_answer(self,theta, beta, left_asymptote):\n",
    "        return left_asymptote + (1 - left_asymptote) * self.sigmoid(theta - beta)\n",
    "\n",
    "    def sigmoid(self,x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def estimate_parameters(self,answers_df, granularity_feature_name=\"assessmentItemID\"):\n",
    "        item_parameters = {\n",
    "            granularity_feature_value: {\"beta\": 0, \"nb_answers\": 0}\n",
    "            for granularity_feature_value in np.unique(\n",
    "                answers_df[granularity_feature_name]\n",
    "            )\n",
    "        }\n",
    "        student_parameters = {\n",
    "            student_id: {\"theta\": 0, \"nb_answers\": 0}\n",
    "            for student_id in np.unique(answers_df.userID)\n",
    "        }\n",
    "\n",
    "        print(\"Parameter estimation is starting...\", flush=True)\n",
    "\n",
    "        for student_id, item_id, left_asymptote, answered_correctly in tqdm(\n",
    "            zip(\n",
    "                answers_df.userID.values,\n",
    "                answers_df[granularity_feature_name].values,\n",
    "                answers_df.left_asymptote.values,\n",
    "                answers_df.answerCode.values,\n",
    "            ),\n",
    "            total=len(answers_df),\n",
    "        ):\n",
    "            theta = student_parameters[student_id][\"theta\"]\n",
    "            beta = item_parameters[item_id][\"beta\"]\n",
    "\n",
    "            item_parameters[item_id][\"beta\"] = self.get_new_beta(\n",
    "                answered_correctly,\n",
    "                beta,\n",
    "                left_asymptote,\n",
    "                theta,\n",
    "                item_parameters[item_id][\"nb_answers\"],\n",
    "            )\n",
    "            student_parameters[student_id][\"theta\"] = self.get_new_theta(\n",
    "                answered_correctly,\n",
    "                beta,\n",
    "                left_asymptote,\n",
    "                theta,\n",
    "                student_parameters[student_id][\"nb_answers\"],\n",
    "            )\n",
    "\n",
    "            item_parameters[item_id][\"nb_answers\"] += 1\n",
    "            student_parameters[student_id][\"nb_answers\"] += 1\n",
    "\n",
    "        print(f\"Theta & beta estimations on {granularity_feature_name} are completed.\")\n",
    "        self.student_parameters = student_parameters\n",
    "        self.item_parameters = item_parameters\n",
    "        return student_parameters, item_parameters\n",
    "    \n",
    "    def estimate_student_parameters(self,answers_df, granularity_feature_name=\"assessmentItemID\"):\n",
    "        student_parameters = {\n",
    "            student_id: {\"theta\": 0, \"nb_answers\": 0}\n",
    "            for student_id in np.unique(answers_df.userID)\n",
    "        }\n",
    "\n",
    "        #print(\"Parameter estimation is starting...\", flush=True)\n",
    "\n",
    "        for student_id, item_id, left_asymptote, answered_correctly in zip(\n",
    "                answers_df.userID.values,\n",
    "                answers_df[granularity_feature_name].values,\n",
    "                answers_df.left_asymptote.values,\n",
    "                answers_df.answerCode.values,\n",
    "            ):\n",
    "            theta = student_parameters[student_id][\"theta\"]\n",
    "            beta = self.item_parameters[item_id][\"beta\"]\n",
    "\n",
    "            student_parameters[student_id][\"theta\"] = self.get_new_theta(\n",
    "                answered_correctly,\n",
    "                beta,\n",
    "                left_asymptote,\n",
    "                theta,\n",
    "                student_parameters[student_id][\"nb_answers\"],\n",
    "            )\n",
    "\n",
    "           \n",
    "            student_parameters[student_id][\"nb_answers\"] += 1\n",
    "\n",
    "        #print(f\"Theta & beta estimations on {granularity_feature_name} are completed.\")\n",
    "        self.student_parameters = student_parameters\n",
    "        return student_parameters\n",
    "\n",
    "    def update_parameters(self,answers_df, student_parameters, item_parameters, granularity_feature_name='assessmentItemID'):\n",
    "        for student_id, item_id, left_asymptote, answered_correctly in zip(\n",
    "            answers_df.userID.values, \n",
    "            answers_df[granularity_feature_name].values, \n",
    "            answers_df.left_asymptote.values, \n",
    "            answers_df.answerCode.values):\n",
    "            if student_id not in student_parameters:\n",
    "                student_parameters[student_id] = {'theta': 0, 'nb_answers': 0}\n",
    "            if item_id not in item_parameters:\n",
    "                item_parameters[item_id] = {'beta': 0, 'nb_answers': 0}\n",
    "                \n",
    "            theta = student_parameters[student_id]['theta']\n",
    "            beta = item_parameters[item_id]['beta']\n",
    "\n",
    "            student_parameters[student_id]['theta'] = self.get_new_theta(\n",
    "                answered_correctly, beta, left_asymptote, theta, student_parameters[student_id]['nb_answers']\n",
    "            )\n",
    "            item_parameters[item_id]['beta'] = self.get_new_beta(\n",
    "                answered_correctly, beta, left_asymptote, theta, item_parameters[item_id]['nb_answers']\n",
    "            )\n",
    "            \n",
    "            student_parameters[student_id]['nb_answers'] += 1\n",
    "            item_parameters[item_id]['nb_answers'] += 1\n",
    "        \n",
    "        \n",
    "        return student_parameters, item_parameters\n",
    "    def run(self,df):\n",
    "        df[\"left_asymptote\"] = 0\n",
    "\n",
    "        print(f\"Dataset of shape {df.shape}\")\n",
    "        print(f\"Columns are {list(df.columns)}\")\n",
    "        \n",
    "        \n",
    "\n",
    "        student_parameters, item_parameters = self.estimate_parameters(df,granularity_feature_name = \"KnowledgeTag\")\n",
    "\n",
    "\n",
    "        b = [\n",
    "            item_parameters[item][\"beta\"]\n",
    "            for student, item in zip(df.userID.values, df.KnowledgeTag.values)\n",
    "        ]\n",
    "        \n",
    "\n",
    "        #beta represents the difficulty of the item \n",
    "        df['elotag'] = b\n",
    "\n",
    "        student_parameters, item_parameters = self.estimate_parameters(df,granularity_feature_name = \"testId\")\n",
    "\n",
    "\n",
    "        b = [\n",
    "            item_parameters[item][\"beta\"]\n",
    "            for student, item in zip(df.userID.values, df.testId.values)\n",
    "        ]\n",
    "        \n",
    "\n",
    "        #beta represents the difficulty of the item \n",
    "        df['elotest'] = b\n",
    "\n",
    "        student_parameters, item_parameters = self.estimate_parameters(df)\n",
    "        \n",
    "        t = [\n",
    "        student_parameters[student][\"theta\"]\n",
    "        for student, item in zip(df.userID.values, df.assessmentItemID.values)\n",
    "        ]\n",
    "        b = [\n",
    "            item_parameters[item][\"beta\"]\n",
    "            for student, item in zip(df.userID.values, df.assessmentItemID.values)\n",
    "        ]\n",
    "\n",
    "\n",
    "        #theta represents the global level of the student\n",
    "        df['elouser'] = t\n",
    "\n",
    "        #beta represents the difficulty of the item \n",
    "        df['eloitem'] = b\n",
    "\n",
    "\n",
    "        return df \n",
    "    \n",
    "    def run_update(self,df):\n",
    "\n",
    "        df[\"left_asymptote\"] = 0\n",
    "        return self.estimate_student_parameters(df)[df.iloc[0,0]]['theta']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset of shape (2517453, 8)\n",
      "Columns are ['userID', 'assessmentItemID', 'testId', 'answerCode', 'Timestamp', 'KnowledgeTag', 'train_valid', 'left_asymptote']\n",
      "Parameter estimation is starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2517453/2517453 [00:18<00:00, 137080.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta & beta estimations on KnowledgeTag are completed.\n",
      "Parameter estimation is starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2517453/2517453 [00:17<00:00, 140402.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta & beta estimations on testId are completed.\n",
      "Parameter estimation is starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2517453/2517453 [00:18<00:00, 135671.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta & beta estimations on assessmentItemID are completed.\n"
     ]
    }
   ],
   "source": [
    "Elo = elo()\n",
    "# ELO Function 적용\n",
    "_train = Elo.run(_train)\n",
    "\n",
    "# 필요없는 column 제거\n",
    "_train = _train.drop(columns=[\"left_asymptote\"])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_86008/2143948767.py:3: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  tmp['seq'] = tmp.groupby('userID')['tem'].apply(lambda x : x.cumsum())\n"
     ]
    }
   ],
   "source": [
    "tmp = _train.copy()\n",
    "tmp['tem'] = 1\n",
    "tmp['seq'] = tmp.groupby('userID')['tem'].apply(lambda x : x.cumsum())\n",
    "tmp['eloupdate'] =0\n",
    "dat_tem = tmp[['userID', 'assessmentItemID', 'answerCode', 'seq']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "_train['eloupdate'] = tmp.apply(lambda x : Elo.run_update(dat_tem[(dat_tem['userID']==x['userID']) & (dat_tem['seq'] < x['seq']) & (dat_tem['seq'] >= x['seq']-100)]) if x['seq'] >= 100 else (Elo.run_update(dat_tem[(dat_tem['userID']==x['userID']) & (dat_tem['seq'] < x['seq'])]) if x['seq'] != 1 else 0),axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = _train.drop_duplicates(['userID'])[['userID','elouser']]\n",
    "items = _train.drop_duplicates(['assessmentItemID'])[['assessmentItemID','eloitem']]\n",
    "tag = _train.drop_duplicates(['KnowledgeTag'])[['KnowledgeTag','elotag']]\n",
    "testid = _train.drop_duplicates(['testId'])[['testId','elotest']]\n",
    "#update = _train.drop_duplicates(['assessmentItemID'])[['assessmentItemID','eloitem']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.to_csv('/opt/ml/input/data/FE/users_elo.csv', index=False)\n",
    "items.to_csv('/opt/ml/input/data/FE/items_elo.csv', index=False)\n",
    "tag.to_csv('/opt/ml/input/data/FE/tag_elo.csv', index=False)\n",
    "testid.to_csv('/opt/ml/input/data/FE/testid_elo.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_test = pd.merge(_test, users, on='userID', how='left')\n",
    "_test = pd.merge(_test, items, on='assessmentItemID', how='left')\n",
    "_test = pd.merge(_test, tag, on='KnowledgeTag', how='left')\n",
    "_test = pd.merge(_test, testid, on='testId', how='left')\n",
    "_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_valid = pd.merge(_valid, users, on='userID', how='left')\n",
    "_valid = pd.merge(_valid, items, on='assessmentItemID', how='left')\n",
    "_valid = pd.merge(_test, tag, on='KnowledgeTag', how='left')\n",
    "_valid = pd.merge(_test, testid, on='testId', how='left')\n",
    "_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.concat([_train,_valid,_test])\n",
    "dat = dat.sort_values(by = ['userID', 'Timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['elo'] = dat.apply(lambda x : 1 / 1 + (np.exp(-(x['elouser']-x['eloitem']))),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = dat.loc[:, [\"userID\", \"Timestamp\"]].groupby(\"userID\").diff().fillna(pd.Timedelta(seconds=0))\n",
    "diff['Timestamp'] = diff['Timestamp'].apply(pd.Timedelta.total_seconds)\n",
    "#diff['Timestamp'] = diff['Timestamp'].apply(lambda x: 0 if x >600 or x<0 else x)\n",
    "dat['solve_time'] = diff['Timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시험 난이도(?)로 추청되는 특성 따로 분류\n",
    "dat['b_category'] = dat['assessmentItemID'].str[2]\n",
    "# 시험지로 추청되는 특성 따로 분류. 뒤에 것이 좋을 것 같은데 일단 제출을 한 것으로 써놓음.\n",
    "dat['test_category'] = dat['assessmentItemID'].str[2] + dat['assessmentItemID'].str[4:7] # dat['assessmentItemID'].str[4:7]\n",
    "dat['problem_id'] = dat['assessmentItemID'].str[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff['Timestamp'] = dat['solve_time']\n",
    "diff['Timestamp'] = pd.qcut(diff['Timestamp'],5)\n",
    "diff['Timestamp'] = diff['Timestamp'].astype(\"str\")\n",
    "dat['category_st_qcut_5'] = diff['Timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['solve_time'] = dat['solve_time'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['last_answerCode'] = dat.groupby(\"userID\")['answerCode'].shift(1).fillna(1)\n",
    "dat['last_answerCode2'] = dat.groupby(\"userID\")['answerCode'].shift(2).fillna(1)\n",
    "dat['last_answerCode3'] = dat.groupby(\"userID\")['answerCode'].shift(3).fillna(1)\n",
    "dat['last_answerCode4'] = dat.groupby(\"userID\")['answerCode'].shift(4).fillna(1)\n",
    "dat['last_answerCode5'] = dat.groupby(\"userID\")['answerCode'].shift(5).fillna(1)\n",
    "dat['last_answerCode6'] = dat.groupby(\"userID\")['answerCode'].shift(6).fillna(1)\n",
    "dat['last_answerCode7'] = dat.groupby(\"userID\")['answerCode'].shift(7).fillna(1)\n",
    "dat['last_answerCode8'] = dat.groupby(\"userID\")['answerCode'].shift(8).fillna(1)\n",
    "dat['last_answerCode9'] = dat.groupby(\"userID\")['answerCode'].shift(9).fillna(1)\n",
    "dat['last_answerCode10'] = dat.groupby(\"userID\")['answerCode'].shift(10).fillna(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['last_answerCode'] = dat['last_answerCode'].astype(int)\n",
    "dat['last_answerCode2'] = dat['last_answerCode2'].astype(int)\n",
    "dat['last_answerCode3'] = dat['last_answerCode3'].astype(int)\n",
    "dat['last_answerCode4'] = dat['last_answerCode4'].astype(int)\n",
    "dat['last_answerCode5'] = dat['last_answerCode5'].astype(int)\n",
    "dat['last_answerCode6'] = dat['last_answerCode6'].astype(int)\n",
    "dat['last_answerCode7'] = dat['last_answerCode7'].astype(int)\n",
    "dat['last_answerCode8'] = dat['last_answerCode8'].astype(int)\n",
    "dat['last_answerCode9'] = dat['last_answerCode9'].astype(int)\n",
    "dat['last_answerCode10'] = dat['last_answerCode10'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.drop(['train_valid'], axis = 1, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['year'] = dat['Timestamp'].dt.year # 연도 정보\n",
    "dat['month'] =  dat['Timestamp'].dt.month # 월 정보\n",
    "dat['day'] =  dat['Timestamp'].dt.day # 일 정보\n",
    "dat['hour'] =  dat['Timestamp'].dt.hour # 시간 정보\n",
    "\n",
    "dat.to_csv('/opt/ml/input/data/FE/FE_total_2_elo3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['elo'].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['solve_time'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
