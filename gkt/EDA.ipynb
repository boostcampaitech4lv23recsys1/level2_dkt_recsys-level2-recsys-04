{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from utils import build_dense_graph\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "class KTDataset(Dataset):\n",
    "    def __init__(self, features, questions, answers):\n",
    "        super(KTDataset, self).__init__()\n",
    "        self.features = features\n",
    "        self.questions = questions\n",
    "        self.answers = answers\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.features[index], self.questions[index], self.answers[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_collate(batch):\n",
    "    (features, questions, answers) = zip(*batch)\n",
    "    features = [torch.LongTensor(feat) for feat in features]\n",
    "    questions = [torch.LongTensor(qt) for qt in questions]\n",
    "    answers = [torch.LongTensor(ans) for ans in answers]\n",
    "    feature_pad = pad_sequence(features, batch_first=True, padding_value=-1)\n",
    "    question_pad = pad_sequence(questions, batch_first=True, padding_value=-1)\n",
    "    answer_pad = pad_sequence(answers, batch_first=True, padding_value=-1)\n",
    "    return feature_pad, question_pad, answer_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_transition_graph(question_list, seq_len_list, indices, student_num, concept_num):\n",
    "    graph = np.zeros((concept_num, concept_num))\n",
    "    student_dict = dict(zip(indices, np.arange(student_num)))\n",
    "    for i in range(student_num):\n",
    "        if i not in student_dict:\n",
    "            continue\n",
    "        questions = question_list[i]\n",
    "        seq_len = seq_len_list[i]\n",
    "        for j in range(seq_len - 1):\n",
    "            pre = questions[j]\n",
    "            next = questions[j + 1]\n",
    "            graph[pre, next] += 1\n",
    "    np.fill_diagonal(graph, 0)\n",
    "    # row normalization\n",
    "    rowsum = np.array(graph.sum(1))\n",
    "    def inv(x):\n",
    "        if x == 0:\n",
    "            return x\n",
    "        return 1. / x\n",
    "    inv_func = np.vectorize(inv)\n",
    "    r_inv = inv_func(rowsum).flatten()\n",
    "    r_mat_inv = np.diag(r_inv)\n",
    "    graph = r_mat_inv.dot(graph)\n",
    "    # covert to tensor\n",
    "    graph = torch.from_numpy(graph).float()\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dkt_graph(file_path, concept_num):\n",
    "    graph = np.loadtxt(file_path)\n",
    "    assert graph.shape[0] == concept_num and graph.shape[1] == concept_num\n",
    "    graph = torch.from_numpy(graph).float()\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"data/assistment_test15.csv\"\n",
    "batch_size = 8\n",
    "graph_type = \"Dense\"\n",
    "dkt_graph_path=None\n",
    "train_ratio=0.6\n",
    "val_ratio=0.2\n",
    "shuffle=True\n",
    "model_type='GKT'\n",
    "use_binary=True\n",
    "res_len=2\n",
    "use_cuda=True\n",
    "r\"\"\"\n",
    "Parameters:\n",
    "    file_path: input file path of knowledge tracing data\n",
    "    batch_size: the size of a student batch\n",
    "    graph_type: the type of the concept graph\n",
    "    shuffle: whether to shuffle the dataset or not\n",
    "    use_cuda: whether to use GPU to accelerate training speed\n",
    "Return:\n",
    "    concept_num: the number of all concepts(or questions) skill_id의 고유값 개수\n",
    "    graph: the static graph is graph type is in ['Dense', 'Transition', 'DKT'], otherwise graph is None; conept_num을 이용하여 만든값\n",
    "    train_data_loader: data loader of the training dataset\n",
    "    valid_data_loader: data loader of the validation dataset\n",
    "    test_data_loader: data loader of the test dataset\n",
    "NOTE: stole some code from https://github.com/lccasagrande/Deep-Knowledge-Tracing/blob/master/deepkt/data_util.py\n",
    "FIXME : 밑에 코드 계속 수정작업중이라 원본 데이터 많이 날아가있고 실행도 안 됩니다. 적절히 걸러서 읽어주세요.\n",
    "1. 데이터 불러오기\n",
    "2. 데이터 전처리(결측치, 범주화 등등)\n",
    "3. skill_with_answer, skill, correct 피쳐를 이용하여 데이터셋 만듬\n",
    "\"\"\"\n",
    "df = pd.read_csv('data/FE_total.csv')\n",
    "# Step 1.1 - Remove questions without KnowledgeTag\n",
    "df.dropna(subset=['KnowledgeTag'], inplace=True)\n",
    "\n",
    "# Step 1.2 - Remove users with a single answer\n",
    "df = df.groupby('userID').filter(lambda q: len(q) > 1).copy()\n",
    "\n",
    "# Step 2 - Enumerate skill id\n",
    "df['skill'], _ = pd.factorize(df['KnowledgeTag'], sort=True)  # we can also use problem_id to represent exercises\n",
    "\n",
    "# Step 3 - Cross skill id with answer to form a synthetic feature\n",
    "# use_binary: (0,1); !use_binary: (1,2,3,4,5,6,7,8,9,10,11,12). Either way, the correct result index is guaranteed to be 1\n",
    "if use_binary:\n",
    "    df['skill_with_answer'] = df['skill'] * 2 + df['answerCode']\n",
    "else:\n",
    "    df['skill_with_answer'] = df['skill'] * res_len + df['answerCode'] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(series):\n",
    "    feature_list.append(series['skill_with_answer'].tolist())\n",
    "    question_list.append(series['skill'].tolist())\n",
    "    answer_list.append(series['answerCode'].eq(1).astype('int').tolist())\n",
    "    seq_len_list.append(series['answerCode'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 - Convert to a sequence per user id and shift features 1 timestep\n",
    "feature_list = []\n",
    "question_list = []\n",
    "answer_list = []\n",
    "seq_len_list = []\n",
    "df.groupby('userID').apply(get_data)\n",
    "question_dim = int(df['skill'].max() + 1)\n",
    "concept_num = question_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "_train = df[df['answerCode'] >= 0]\n",
    "_test = df[df['answerCode'] < 0]\n",
    "user_final_time = _train.groupby('userID')['Timestamp'].max()\n",
    "_train['train_valid'] = _train.apply(lambda x : -1 if x.Timestamp == user_final_time[x.userID] else x['answerCode'], axis = 1)\n",
    "_valid = _train[_train['train_valid'] < 0]\n",
    "_train = _train[_train['train_valid'] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max seq_len:  1860\n",
      "student num:  14884\n",
      "feature_dim:  1824\n",
      "question_dim:  912\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df.groupby('userID').apply(get_data)\n",
    "max_seq_len = np.max(seq_len_list)\n",
    "print('max seq_len: ', max_seq_len)\n",
    "student_num = len(seq_len_list)\n",
    "print('student num: ', student_num)\n",
    "feature_dim = int(df['skill_with_answer'].max() + 1)\n",
    "print('feature_dim: ', feature_dim)\n",
    "question_dim = int(df['skill'].max() + 1)\n",
    "print('question_dim: ', question_dim)\n",
    "concept_num = question_dim\n",
    "\n",
    "# Step 5 train / valid / test 만들기\n",
    "# Step 5 - train / valid / test\n",
    "feature_list = []\n",
    "question_list = []\n",
    "answer_list = []\n",
    "seq_len_list = []\n",
    "_train.groupby('userID').apply(get_data)\n",
    "train_dataset = KTDataset(feature_list, question_list, answer_list)\n",
    "\n",
    "feature_list = []\n",
    "question_list = []\n",
    "answer_list = []\n",
    "seq_len_list = []\n",
    "_valid.groupby('userID').apply(get_data)\n",
    "val_dataset = KTDataset(feature_list, question_list, answer_list)\n",
    "\n",
    "feature_list = []\n",
    "question_list = []\n",
    "answer_list = []\n",
    "seq_len_list = []\n",
    "_test.groupby('userID').apply(get_data)\n",
    "test_dataset = KTDataset(feature_list, question_list, answer_list)\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle, collate_fn=pad_collate)\n",
    "valid_data_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=shuffle, collate_fn=pad_collate)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=shuffle, collate_fn=pad_collate)\n",
    "\n",
    "graph = None\n",
    "if model_type == 'GKT':\n",
    "    if graph_type == 'Dense':\n",
    "        graph = build_dense_graph(concept_num)\n",
    "    elif graph_type == 'Transition':\n",
    "        graph = build_transition_graph(question_list, seq_len_list, train_dataset.indices, student_num, concept_num)\n",
    "    elif graph_type == 'DKT':\n",
    "        graph = build_dkt_graph(dkt_graph_path, concept_num)\n",
    "    if use_cuda and graph_type in ['Dense', 'Transition', 'DKT']:\n",
    "        graph = graph.cuda()\n",
    "    # return concept_num, graph, train_data_loader, valid_data_loader, test_data_loader"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 ('gkt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "93f74964422d10ad4f210b5dac117a43201084ec175b6f67edb46c521df5654f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
