{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-24T09:49:29.375544Z",
          "start_time": "2021-05-24T09:49:28.999092Z"
        },
        "id": "Uq_TJqbdhfQu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import accuracy_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "path = '/opt/ml/input/data/'\n",
        "# # train = pd.read_csv(path + 'train_data.csv')\n",
        "# # test = pd.read_csv(path + 'test_data.csv')\n",
        "dat = pd.read_csv(path + 'FE/FE_total.csv')\n",
        "\n",
        "dat = dat.sort_values(by = ['userID', 'Timestamp'])\n",
        "dat['tem'] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-24T09:49:29.678737Z",
          "start_time": "2021-05-24T09:49:29.376581Z"
        },
        "id": "s6qgJ8MLhfQw"
      },
      "outputs": [],
      "source": [
        "_train = dat[dat['answerCode'] >= 0]\n",
        "_test = dat[dat['answerCode'] == -1]\n",
        "\n",
        "# 데이터 증강하는 법.\n",
        "def data_argument(train):\n",
        "    _train = train.copy()\n",
        "    _train.reset_index(drop = True, inplace= True)\n",
        "    _train.loc[_train.drop_duplicates(subset='userID', keep = 'last').index, 'tem'] = -1\n",
        "    _valid = _train[_train['tem'] == -1]\n",
        "    _train = _train[_train['tem'] == 0]\n",
        "\n",
        "    return _train, _valid\n",
        "\n",
        "_train_x, _valid = data_argument(_train)\n",
        "_train_x_1, _train_1 = data_argument(_train_x)\n",
        "_train_x_2, _train_2 = data_argument(_train_x_1)\n",
        "_train_x_3, _train_3 = data_argument(_train_x_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "def data_merge(_train_x, _train_y): \n",
        "    # _train_x : 값 제공하는 전체 DB, _train_y : 현재 맞춰야 하는 유저와 아이템 상태.\n",
        "    # 유저 단위 변수 추가\n",
        "    tem1 = _train_x.groupby('userID')['answerCode']\n",
        "    tem1 = pd.DataFrame({'answer_mean' : tem1.mean(), 'answer_cnt':tem1.count()}).reset_index()\n",
        "    tem2 = _train_x.groupby('userID')['solve_time']\n",
        "    tem2 = pd.DataFrame({'time_mean' : tem2.mean()}).reset_index()\n",
        "    tem3 = pd.DataFrame({'tag_mode' : _train_x.groupby('userID')['KnowledgeTag'].agg(pd.Series.mode)})\n",
        "    tem3['tag_mode'] = tem3['tag_mode'].apply(lambda x : x if str(type(x)) ==\"<class 'numpy.int64'>\" else x[0])\n",
        "    tem4 = _train_x.groupby('userID')['answerCode'].apply(lambda x : x.iloc[-3:])\n",
        "    tem4 = pd.DataFrame({'last3_mean' : tem4.groupby('userID').mean()})\n",
        "\n",
        "    user_df = pd.merge(tem1, tem2, on=['userID'], how='left')\n",
        "    user_df = pd.merge(user_df, tem3, on=['userID'], how='left')\n",
        "    user_df = pd.merge(user_df, tem4, on=['userID'], how='left')\n",
        "\n",
        "    # 아이템 단위 변수 추가.\n",
        "    correct_k = _train_x.groupby(['assessmentItemID'])['answerCode'].agg(['mean', 'sum'])\n",
        "    correct_k.columns = [\"item_mean\", 'item_sum']\n",
        "    correct_k.reset_index(inplace=True)\n",
        "\n",
        "    _train_y = pd.merge(_train_y[['userID', 'assessmentItemID', 'answerCode']], user_df, on=['userID'], how='left')\n",
        "    _train_y = pd.merge(_train_y, correct_k, on=['assessmentItemID'], how='left')\n",
        "\n",
        "    return _train_y.drop(['userID','assessmentItemID'],axis=1)\n",
        "\n",
        "test = data_merge(_train, _test)\n",
        "valid = data_merge(_train_x, _valid)\n",
        "train_1 = data_merge(_train_x_1, _train_1)\n",
        "train_2 = data_merge(_train_x_2, _train_2)\n",
        "train_3 = data_merge(_train_x_3, _train_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TRAIN AUC : 0.867752911350715 ACC : 0.7841530054644809\n",
            "\n",
            "VALID AUC : 0.7850297282254111 ACC : 0.7141897339424885\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train = pd.concat([train_1,train_2,train_3])\n",
        "\n",
        "model = LGBMClassifier()\n",
        "model.fit(train.drop(['answerCode'],axis=1), train['answerCode'])\n",
        "preds = model.predict_proba(train.drop(['answerCode'],axis=1))[:,1]\n",
        "\n",
        "acc = accuracy_score(train['answerCode'], np.where(preds >= 0.5, 1, 0))\n",
        "auc = roc_auc_score(train['answerCode'], preds)\n",
        "print(f'TRAIN AUC : {auc} ACC : {acc}\\n')\n",
        "\n",
        "preds = model.predict_proba(valid.drop(['answerCode'],axis=1))[:,1]\n",
        "acc = accuracy_score(valid['answerCode'], np.where(preds >= 0.5, 1, 0))\n",
        "auc = roc_auc_score(valid['answerCode'], preds)\n",
        "\n",
        "print(f'VALID AUC : {auc} ACC : {acc}\\n')\n",
        "# train 대비 Valid가 낮다. valid는 리더보드와 거의 동일하다.\n",
        "# train에 모델 과적합. => 과적합 방지 하이퍼파라미터 튜닝 + 데이터 증강필요?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# submission 제출하기 위한 코드\n",
        "\n",
        "test_pred = model.predict_proba(test.drop(['answerCode'],axis=1))[:,1]\n",
        "test['prediction'] = test_pred\n",
        "submission = test['prediction'].reset_index(drop = True).reset_index()\n",
        "submission.rename(columns = {'index':'id'}, inplace = True)\n",
        "submission.to_csv('../output/sequence_LGBM_submission3.csv', index = False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.6.9 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
