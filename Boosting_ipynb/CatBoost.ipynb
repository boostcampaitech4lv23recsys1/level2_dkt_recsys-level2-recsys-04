{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pdb\n",
    "from scipy.sparse import csr_matrix, linalg\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "#import lightgbm as lgb\n",
    "\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "\n",
    "import optuna\n",
    "from optuna import Trial, visualization\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_csv('/opt/ml/input/data/FE_total2.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_train = dat[dat['answerCode'] >= 0]\n",
    "_test = dat[dat['answerCode'] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2525956, 744)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(_train), len(_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "split() missing 1 required positional argument: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [17], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m skf\u001b[39m.\u001b[39mget_n_splits(_train, _test)\n\u001b[1;32m      3\u001b[0m folds \u001b[39m=\u001b[39m []\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfor\u001b[39;00m train_idx \u001b[39min\u001b[39;00m skf\u001b[39m.\u001b[39;49msplit(_train):\n\u001b[1;32m      5\u001b[0m     folds\u001b[39m.\u001b[39mappend((train_idx))\n",
      "\u001b[0;31mTypeError\u001b[0m: split() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=2)\n",
    "skf.get_n_splits(_train, _test)\n",
    "folds = []\n",
    "for train_idx in skf.split(_train):\n",
    "    folds.append((train_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## book 테이블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# books 테이블 전처리 부분 입니다.\n",
    "# books의 이미지 변수를 지워줍니다.\n",
    "# 제목과 요약 내용 변수를 지웁니다. \n",
    "# (이 변수들은 추후 사용 가능할수도 있으나 일단 지웁니다.)\n",
    "# books의 publisher 변수 중 이름이 비슷한 변수들을 찾아 하나로 통일해줍니다.\n",
    "books.drop(['summary', 'img_url', 'img_path'], axis = 1, inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books['book_title']= books['book_title'].apply(lambda x: ''.join(x.split()).strip())\n",
    "books['book_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# books의 카테고리 부분.\n",
    "\n",
    "# 대괄호 써있는 카테고리 전치리\n",
    "books.loc[books[books['category'].notnull()].index, 'category'] = books[books['category'].notnull()]['category'].apply(lambda x: re.sub('[\\W_]+',' ',x).strip())\n",
    "# 모두 소문자로 통일\n",
    "books['category'] = books['category'].str.lower()\n",
    "\n",
    "# 수작업으로 higt 카테고리로 통합\n",
    "categories = ['garden','crafts','physics','adventure','music','fiction','nonfiction','science','science fiction','social','homicide',\n",
    " 'sociology','disease','religion','christian','philosophy','psycholog','mathemat','agricult','environmental',\n",
    " 'business','poetry','drama','literary','travel','motion picture','children','cook','literature','electronic',\n",
    " 'humor','animal','bird','photograph','computer','house','ecology','family','architect','camp','criminal','language','india']\n",
    "\n",
    "books['category_high'] = books['category'].copy()\n",
    "for category in categories:\n",
    "    books.loc[books[books['category'].str.contains(category,na=False)].index,'category_high'] = category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# language와 category_high NULL 값을 최빈값으로 채웁니다.\n",
    "# 근거 : language == en일 때, category_high == fiction 일 때와\n",
    "# 근거 : 값이 NULL 일 때 rating 평균이 7.0x로 유사한 형태.\n",
    "books['language'].fillna('en', inplace = True)\n",
    "books['category_high'].fillna('fiction', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출판연도 1970, 1980, 1990, 2000, 2020 으로 범주화 시킵니다.\n",
    "# 딥러닝 과정에서 범주화 시키는 것이 유리합니다.\n",
    "# 근거 : develop 파일에서 여러번 실험 결과 본 기준이 가장 rating을 잘 구분함.\n",
    "\n",
    "books['years'] = books['year_of_publication'].copy()\n",
    "books['years'][books['year_of_publication'] < 1970] = 1970\n",
    "books['years'][(books['year_of_publication'] < 1980) * (books['year_of_publication'] >= 1970)] = 1980\n",
    "books['years'][(books['year_of_publication'] < 1990) * (books['year_of_publication'] >= 1980)] = 1990\n",
    "books['years'][(books['year_of_publication'] < 2000) * (books['year_of_publication'] >= 1990)] = 2000\n",
    "books['years'][(books['year_of_publication'] >= 2000)] = 2020\n",
    "books['years'] = books['years'].astype('str')\n",
    "#books['years'] = books['years'].astype('int')\n",
    "books.drop(['year_of_publication', 'category'], axis = 1, inplace = True)\n",
    "\n",
    "books.to_csv('data/cat_books.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## user 테이블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users['location'] = users['location'].str.replace(r'[^0-9a-zA-Z:,]', '') # 특수문자 제거\n",
    "\n",
    "users['location_city'] = users['location'].apply(lambda x: x.split(',')[0].strip())\n",
    "users['location_state'] = users['location'].apply(lambda x: x.split(',')[1].strip())\n",
    "users['location_country'] = users['location'].apply(lambda x: x.split(',')[2].strip())\n",
    "\n",
    "users = users.replace('na', np.nan) #특수문자 제거로 n/a가 na로 바뀌게 되었습니다. 따라서 이를 컴퓨터가 인식할 수 있는 결측값으로 변환합니다.\n",
    "users = users.replace('', np.nan) # 일부 경우 , , ,으로 입력된 경우가 있었으므로 이런 경우에도 결측값으로 변환합니다.\n",
    "\n",
    "modify_location = users[(users['location_country'].isna())&(users['location_city'].notnull())]['location_city'].values\n",
    "location = users[(users['location'].str.contains('seattle'))&(users['location_country'].notnull())]['location'].value_counts().index[0]\n",
    "\n",
    "location_list = []\n",
    "for location in modify_location:\n",
    "    try:\n",
    "        right_location = users[(users['location'].str.contains(location))&(users['location_country'].notnull())]['location'].value_counts().index[0]\n",
    "        location_list.append(right_location)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for location in location_list:\n",
    "    users.loc[users[users['location_city']==location.split(',')[0]].index,'location_state'] = location.split(',')[1]\n",
    "    users.loc[users[users['location_city']==location.split(',')[0]].index,'location_country'] = location.split(',')[2]\n",
    "\n",
    "loc_city2idx = {v:k for k,v in enumerate(users['location_city'].unique())}\n",
    "loc_state2idx = {v:k for k,v in enumerate(users['location_state'].unique())}\n",
    "loc_country2idx = {v:k for k,v in enumerate(users['location_country'].unique())}\n",
    "\n",
    "users['location_city'] = users['location_city'].map(loc_city2idx)\n",
    "users['location_state'] = users['location_state'].map(loc_state2idx)\n",
    "users['location_country'] = users['location_country'].map(loc_country2idx)\n",
    "\n",
    "users.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users['fix_age'] = users['age'].copy()\n",
    "users['fix_age'][users['age'] < 10] = 10\n",
    "users['fix_age'][(users['age'] < 20) & (users['age'] >= 10)] = 20\n",
    "users['fix_age'][(users['age'] < 30) & (users['age'] >= 20)] = 30\n",
    "users['fix_age'][(users['age'] < 35) & (users['age'] >= 30)] = 35\n",
    "users['fix_age'][(users['age'] < 40) & (users['age'] >= 35)] = 40\n",
    "users['fix_age'][(users['age'] < 50) & (users['age'] >= 40)] = 50\n",
    "users['fix_age'][users['age'] >= 50] = 100\n",
    "users['fix_age'].fillna(10, inplace = True)\n",
    "users['fix_age'] = users['fix_age'].astype('str') # users['fix_age'] = users['fix_age'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = users[['user_id', 'location_city', 'location_state', 'location_country','fix_age']]\n",
    "users.to_csv('data/cat_users.csv', index = False)\n",
    "users.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rating 테이블과 merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 완료한 books와 users 테이블을 이용해 rating 테이블과 merge 하기.\n",
    "train_ratings = pd.read_csv(path+'train_ratings.csv')\n",
    "test_ratings = pd.read_csv(path+'test_ratings.csv')\n",
    "\n",
    "train_ratings = pd.merge(train_ratings,books, how='right',on='isbn')\n",
    "train_ratings.dropna(subset=['rating'], inplace = True)\n",
    "train_ratings = pd.merge(train_ratings, users, how='right',on='user_id')\n",
    "train_ratings.dropna(subset=['rating'], inplace = True)\n",
    "\n",
    "test_ratings['index'] = test_ratings.index\n",
    "test_ratings = pd.merge(test_ratings,books, how='right',on='isbn')\n",
    "test_ratings.dropna(subset=['rating'], inplace = True)\n",
    "test_ratings = pd.merge(test_ratings, users, how='right',on='user_id')\n",
    "test_ratings.dropna(subset=['rating'], inplace = True)\n",
    "test_ratings = test_ratings.sort_values('index')\n",
    "test_ratings.drop(['index'], axis=1, inplace=True)\n",
    "\n",
    "train_ratings['user_id'] = train_ratings['user_id'].astype('str')\n",
    "test_ratings['user_id'] = test_ratings['user_id'].astype('str')\n",
    "\n",
    "train_ratings['location_city'] = train_ratings['location_city'].astype('str')\n",
    "test_ratings['location_city'] = test_ratings['location_city'].astype('str')\n",
    "\n",
    "train_ratings['location_state'] = train_ratings['location_state'].astype('str')\n",
    "test_ratings['location_state'] = test_ratings['location_state'].astype('str')\n",
    "\n",
    "train_ratings['location_country'] = train_ratings['location_country'].astype('str')\n",
    "test_ratings['location_country'] = test_ratings['location_country'].astype('str')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratings.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## streamlit 코드를 위한 간단한 모델링\n",
    "# import joblib\n",
    "\n",
    "# params_cat = {\n",
    "#     \"task_type\" : \"GPU\",\n",
    "#     \"devices\" : '0',\n",
    "#     \"random_state\": SEED,\n",
    "#     'learning_rate': 0.04574578205475402, \n",
    "#     'bagging_temperature': 0.12172958098369972, \n",
    "#     'n_estimators': 2000, \n",
    "#     'max_depth': 8, \n",
    "#     'random_strength': 28, \n",
    "#     'l2_leaf_reg': 1.6285455533915874e-05, \n",
    "#     'min_child_samples': 18, \n",
    "#     'max_bin': 441, \n",
    "#     'od_type': 'Iter',\n",
    "#     \"cat_features\" : list(train_ratings.drop(['rating'],axis = 1).columns),\n",
    "# }\n",
    "\n",
    "# model = CatBoostRegressor(**params_cat)\n",
    "# model.fit(\n",
    "#     train_ratings.drop(['rating'],axis = 1),\n",
    "#     train_ratings['rating'],\n",
    "#     #early_stopping_rounds=10,\n",
    "#     verbose=False,\n",
    "# )\n",
    "\n",
    "# joblib.dump(model, './MODEL/Cat_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=SEED)\n",
    "folds = []\n",
    "for train_idx, valid_idx in skf.split(train_ratings, train_ratings['rating']):\n",
    "    folds.append((train_idx,valid_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_models={}\n",
    "\n",
    "cat_features = list(range(1, 10))\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        \"random_state\":42,\n",
    "        \"objective\" : \"RMSE\",\n",
    "        \"cat_features\" : list(train_ratings.drop(['rating'],axis = 1).columns),\n",
    "        'learning_rate' : trial.suggest_loguniform('learning_rate', 0.01, 0.5),\n",
    "        'bagging_temperature' :trial.suggest_loguniform('bagging_temperature', 0.01, 100.00),\n",
    "        \"n_estimators\":trial.suggest_int(\"n_estimators\", 1000, 10000),\n",
    "        \"max_depth\":trial.suggest_int(\"max_depth\", 4, 16),\n",
    "        'random_strength' :trial.suggest_int('random_strength', 0, 100),\n",
    "    #   \"colsample_bylevel\":trial.suggest_float(\"colsample_bylevel\", 0.4, 1.0), 이거 때메 GPU 안돌아감\n",
    "        \"l2_leaf_reg\":trial.suggest_float(\"l2_leaf_reg\",1e-8,3e-5),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "        \"max_bin\": trial.suggest_int(\"max_bin\", 200, 500),\n",
    "        'od_type': trial.suggest_categorical('od_type', ['IncToDec', 'Iter']),\n",
    "    }\n",
    "\n",
    "    model = CatBoostRegressor(**param, task_type = 'GPU', devices = '0')\n",
    "\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        verbose=100\n",
    "    )\n",
    "\n",
    "    cat_pred = model.predict(X_valid)\n",
    "    log_score = rmse(y_valid, cat_pred)\n",
    "\n",
    "    return log_score\n",
    "\n",
    "for fold in range(0,10):\n",
    "    print(f'===================================={fold+1}============================================')\n",
    "    train_idx, valid_idx = folds[fold]\n",
    "    X_train = train_ratings.drop(['rating'],axis = 1).iloc[train_idx]\n",
    "    X_valid = train_ratings.drop(['rating'],axis = 1).iloc[valid_idx]\n",
    "    y_train = train_ratings['rating'].iloc[train_idx]\n",
    "    y_valid = train_ratings['rating'].iloc[valid_idx]\n",
    "\n",
    "    sampler = optuna.samplers.TPESampler(seed=42)\n",
    "    study = optuna.create_study(\n",
    "        study_name = 'cat_parameter_opt',\n",
    "        direction = 'minimize',\n",
    "        sampler = sampler,\n",
    "    )\n",
    "    study.optimize(objective, n_trials=10)\n",
    "\n",
    "\n",
    "    model = CatBoostRegressor(**study.best_params, task_type = 'GPU', \n",
    "                              devices = '0', random_state = SEED, objective = 'RMSE', \n",
    "                              cat_features = list(train_ratings.drop(['rating'],axis = 1).columns))\n",
    "    model.fit(X_train, y_train)\n",
    "                \n",
    "    pred = model.predict(test_ratings.drop(['rating'],axis = 1))\n",
    "    test_ratings[f'pred_{fold}'] = pred\n",
    "    print(f'================================================================================\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratings['rating'] = (test_ratings['pred_0'] + test_ratings['pred_1'] + test_ratings['pred_2'] + test_ratings['pred_3'] + test_ratings['pred_4'] +test_ratings['pred_5'] +\n",
    "                                            test_ratings['pred_6'] + test_ratings['pred_7'] + test_ratings['pred_8'] + test_ratings['pred_9']) / 10\n",
    "test = test_ratings[['user_id', 'isbn', 'rating']]\n",
    "#test.to_csv('../submit/CAT_10Fold.csv', index = False)\n",
    "test.to_csv('submit/CatBoost.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(importance,names,model_type):\n",
    "    \n",
    "    feature_importance = np.array(importance)\n",
    "    feature_names = np.array(names)\n",
    "    \n",
    "    data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
    "    fi_df = pd.DataFrame(data)\n",
    "    \n",
    "    fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
    "\n",
    "    plt.figure(figsize=(20,9))\n",
    "\n",
    "    sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'])\n",
    "\n",
    "    plt.title(model_type + ' Feature Importance')\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.ylabel('Feature Names')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_feature_importance(model.get_feature_importance(), train_ratings.drop(['rating'],axis = 1).columns, 'CATBOOST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
