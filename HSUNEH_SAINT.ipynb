{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# import pytorch_lightning as pl\n",
    "from torch import nn\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    device = torch.device(\"cuda\")\n",
    "    MAX_SEQ = 100\n",
    "    EMBED_DIMS = 512\n",
    "    ENC_HEADS = DEC_HEADS = 8\n",
    "    NUM_ENCODER = NUM_DECODER = 4\n",
    "    BATCH_SIZE = 32\n",
    "    TRAIN_FILE = \"/data/train_data.csv\"\n",
    "    TOTAL_EXE = 13523\n",
    "    TOTAL_CAT = 10000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.데이터 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train의 Column 종류\n",
    "\n",
    "row_id, timestamp, user_id, content_id, content_type_id,\n",
    "\n",
    "task_container_id, user_answer, answered_correctly, prior_question_elapsed_time, prior_question_had_explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리 DKT\n",
    "\n",
    "userID,assessmentItemID,testId,answerCode,Timestamp,KnowledgeTag\n",
    "\n",
    "공통적으로 User id, timestamp 있고\n",
    "\n",
    "콘텐츠적으로 나누면 우리 dkt 는 3개정도 분류될거 같고,\n",
    "\n",
    "saint+이기 때문에 time 에 관해서 더 프로세싱하면 될거 같다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders():\n",
    "    dtypes = {'timestamp': 'int64', 'user_id': 'int32', 'content_id': 'int16',\n",
    "              'answered_correctly': 'int8', \"content_type_id\": \"int8\",\n",
    "              \"prior_question_elapsed_time\": \"float32\", \"task_container_id\": \"int16\"}\n",
    "    print(\"loading csv.....\")\n",
    "    train_df = pd.read_csv(Config.TRAIN_FILE, usecols=[\n",
    "                           1, 2, 3, 4, 5, 7, 8], dtype=dtypes, nrows=90e6)\n",
    "    print(\"shape of dataframe :\", train_df.shape)\n",
    "\n",
    "    train_df = train_df[train_df.content_type_id == 0]\n",
    "    train_df.prior_question_elapsed_time.fillna(0, inplace=True)\n",
    "    train_df.prior_question_elapsed_time /= 1000\n",
    "    # train_df.prior_question_elapsed_time.clip(lower=0,upper=300,inplace=True)\n",
    "    train_df.prior_question_elapsed_time = train_df.prior_question_elapsed_time.astype(\n",
    "        np.int)\n",
    "\n",
    "    train_df = train_df.sort_values(\n",
    "        [\"timestamp\"], ascending=True).reset_index(drop=True)\n",
    "    n_skills = train_df.content_id.nunique()\n",
    "    print(\"no. of skills :\", n_skills)\n",
    "    print(\"shape after exlusion:\", train_df.shape)\n",
    "\n",
    "    # grouping based on user_id to get the data supplu\n",
    "    print(\"Grouping users...\")\n",
    "    group = train_df[[\"user_id\", \"content_id\", \"answered_correctly\", \"prior_question_elapsed_time\", \"task_container_id\"]]\\\n",
    "        .groupby(\"user_id\")\\\n",
    "        .apply(lambda r: (r.content_id.values, r.answered_correctly.values,\n",
    "                          r.prior_question_elapsed_time.values, r.task_container_id.values))\n",
    "    del train_df\n",
    "    gc.collect()\n",
    "    print(\"splitting\")\n",
    "    train, val = train_test_split(group, test_size=0.2)\n",
    "    print(\"train size: \", train.shape, \"validation size: \", val.shape)\n",
    "    train_dataset = DKTDataset(train, max_seq=Config.MAX_SEQ)\n",
    "    val_dataset = DKTDataset(val, max_seq=Config.MAX_SEQ)\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=Config.BATCH_SIZE,\n",
    "                              num_workers=8,\n",
    "                              shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset,\n",
    "                            batch_size=Config.BATCH_SIZE,\n",
    "                            num_workers=8,\n",
    "                            shuffle=False)\n",
    "    del train_dataset, val_dataset\n",
    "    gc.collect()\n",
    "    return train_loader, val_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_loader, val_loader = get_dataloaders()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 멀티헤드어텐션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackedNMultiHeadAttention(nn.Module):\n",
    "    def __init__(self, n_stacks, n_dims, n_heads, seq_len, n_multihead=1, dropout=0.0):\n",
    "        super(StackedNMultiHeadAttention, self).__init__()\n",
    "        self.n_stacks = n_stacks\n",
    "        self.n_multihead = n_multihead\n",
    "        self.n_dims = n_dims\n",
    "        self.norm_layers = nn.LayerNorm(n_dims)\n",
    "        # n_stacks has n_multiheads each\n",
    "        self.multihead_layers = nn.ModuleList(n_stacks*[nn.ModuleList(n_multihead*[nn.MultiheadAttention(embed_dim=n_dims,\n",
    "                                                                                                         num_heads=n_heads,\n",
    "                                                                                                         dropout=dropout), ]), ])\n",
    "        self.ffn = nn.ModuleList(n_stacks*[FFN(n_dims)])\n",
    "        self.mask = torch.triu(torch.ones(seq_len, seq_len),\n",
    "                               diagonal=1).to(dtype=torch.bool)\n",
    "\n",
    "    def forward(self, input_q, input_k, input_v, encoder_output=None, break_layer=None):\n",
    "        for stack in range(self.n_stacks):\n",
    "            for multihead in range(self.n_multihead):\n",
    "                norm_q = self.norm_layers(input_q)\n",
    "                norm_k = self.norm_layers(input_k)\n",
    "                norm_v = self.norm_layers(input_v)\n",
    "                heads_output, _ = self.multihead_layers[stack][multihead](query=norm_q.permute(1, 0, 2),\n",
    "                                                                          key=norm_k.permute(\n",
    "                                                                              1, 0, 2),\n",
    "                                                                          value=norm_v.permute(\n",
    "                                                                              1, 0, 2),\n",
    "                                                                          attn_mask=self.mask.to(Config.device))\n",
    "                heads_output = heads_output.permute(1, 0, 2)\n",
    "                #assert encoder_output != None and break_layer is not None\n",
    "                if encoder_output != None and multihead == break_layer:\n",
    "                    assert break_layer <= multihead, \" break layer should be less than multihead layers and postive integer\"\n",
    "                    input_k = input_v = encoder_output\n",
    "                    input_q = input_q + heads_output\n",
    "                else:\n",
    "                    input_q = input_q + heads_output\n",
    "                    input_k = input_k + heads_output\n",
    "                    input_v = input_v + heads_output\n",
    "            last_norm = self.norm_layers(heads_output)\n",
    "            ffn_output = self.ffn[stack](last_norm)\n",
    "            ffn_output = ffn_output + heads_output\n",
    "        # after loops = input_q = input_k = input_v\n",
    "        return ffn_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderEmbedding(nn.Module):\n",
    "    def __init__(self, n_exercises, n_categories, n_dims, seq_len):\n",
    "        super(EncoderEmbedding, self).__init__()\n",
    "        self.n_dims = n_dims\n",
    "        self.seq_len = seq_len\n",
    "        self.exercise_embed = nn.Embedding(n_exercises, n_dims)\n",
    "        self.category_embed = nn.Embedding(n_categories, n_dims)\n",
    "        self.position_embed = nn.Embedding(seq_len, n_dims)\n",
    "\n",
    "    def forward(self, exercises, categories):\n",
    "        e = self.exercise_embed(exercises)\n",
    "        c = self.category_embed(categories)\n",
    "        seq = torch.arange(self.seq_len, device=Config.device).unsqueeze(0)\n",
    "        p = self.position_embed(seq)\n",
    "        return p + c + e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderEmbedding(nn.Module):\n",
    "    def __init__(self, n_responses, n_dims, seq_len):\n",
    "        super(DecoderEmbedding, self).__init__()\n",
    "        self.n_dims = n_dims\n",
    "        self.seq_len = seq_len\n",
    "        self.response_embed = nn.Embedding(n_responses, n_dims)\n",
    "        self.time_embed = nn.Linear(1, n_dims, bias=False)\n",
    "        self.position_embed = nn.Embedding(seq_len, n_dims)\n",
    "\n",
    "    def forward(self, responses):\n",
    "        e = self.response_embed(responses)\n",
    "        seq = torch.arange(self.seq_len, device=Config.device).unsqueeze(0)\n",
    "        p = self.position_embed(seq)\n",
    "        return p + e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 메인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlusSAINTModule(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        # n_encoder,n_detotal_responses,seq_len,max_time=300+1\n",
    "        super(PlusSAINTModule, self).__init__()\n",
    "        self.loss = nn.BCEWithLogitsLoss()\n",
    "        self.encoder_layer = StackedNMultiHeadAttention(n_stacks=Config.NUM_DECODER,\n",
    "                                                        n_dims=Config.EMBED_DIMS,\n",
    "                                                        n_heads=Config.DEC_HEADS,\n",
    "                                                        seq_len=Config.MAX_SEQ,\n",
    "                                                        n_multihead=1, dropout=0.0)\n",
    "        self.decoder_layer = StackedNMultiHeadAttention(n_stacks=Config.NUM_ENCODER,\n",
    "                                                        n_dims=Config.EMBED_DIMS,\n",
    "                                                        n_heads=Config.ENC_HEADS,\n",
    "                                                        seq_len=Config.MAX_SEQ,\n",
    "                                                        n_multihead=2, dropout=0.0)\n",
    "        self.encoder_embedding = EncoderEmbedding(n_exercises=Config.TOTAL_EXE,\n",
    "                                                  n_categories=Config.TOTAL_CAT,\n",
    "                                                  n_dims=Config.EMBED_DIMS, seq_len=Config.MAX_SEQ)\n",
    "        self.decoder_embedding = DecoderEmbedding(\n",
    "            n_responses=3, n_dims=Config.EMBED_DIMS, seq_len=Config.MAX_SEQ)\n",
    "        self.elapsed_time = nn.Linear(1, Config.EMBED_DIMS)\n",
    "        self.fc = nn.Linear(Config.EMBED_DIMS, 1)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        enc = self.encoder_embedding(\n",
    "            exercises=x[\"input_ids\"], categories=x['input_cat'])\n",
    "        dec = self.decoder_embedding(responses=y)\n",
    "        elapsed_time = x[\"input_rtime\"].unsqueeze(-1).float()\n",
    "        ela_time = self.elapsed_time(elapsed_time)\n",
    "        dec = dec + ela_time\n",
    "        # this encoder\n",
    "        encoder_output = self.encoder_layer(input_k=enc,\n",
    "                                            input_q=enc,\n",
    "                                            input_v=enc)\n",
    "        #this is decoder\n",
    "        decoder_output = self.decoder_layer(input_k=dec,\n",
    "                                            input_q=dec,\n",
    "                                            input_v=dec,\n",
    "                                            encoder_output=encoder_output,\n",
    "                                            break_layer=1)\n",
    "        # fully connected layer\n",
    "        out = self.fc(decoder_output)\n",
    "        return out.squeeze()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters())\n",
    "\n",
    "    def training_step(self, batch, batch_ids):\n",
    "        input, labels = batch\n",
    "        target_mask = (input[\"input_ids\"] != 0)\n",
    "        out = self(input, labels)\n",
    "        loss = self.loss(out.float(), labels.float())\n",
    "        out = torch.masked_select(out, target_mask)\n",
    "        out = torch.sigmoid(out)\n",
    "        labels = torch.masked_select(labels, target_mask)\n",
    "        self.log(\"train_loss\", loss, on_step=True, prog_bar=True)\n",
    "        return {\"loss\": loss, \"outs\": out, \"labels\": labels}\n",
    "\n",
    "    def training_epoch_end(self, training_ouput):\n",
    "        out = np.concatenate([i[\"outs\"].cpu().detach().numpy()\n",
    "                              for i in training_ouput]).reshape(-1)\n",
    "        labels = np.concatenate([i[\"labels\"].cpu().detach().numpy()\n",
    "                                 for i in training_ouput]).reshape(-1)\n",
    "        auc = roc_auc_score(labels, out)\n",
    "        self.print(\"train auc\", auc)\n",
    "        self.log(\"train_auc\", auc)\n",
    "\n",
    "    def validation_step(self, batch, batch_ids):\n",
    "        input, labels = batch\n",
    "        target_mask = (input[\"input_ids\"] != 0)\n",
    "        out = self(input, labels)\n",
    "        loss = self.loss(out.float(), labels.float())\n",
    "        out = torch.masked_select(out, target_mask)\n",
    "        out = torch.sigmoid(out)\n",
    "        labels = torch.masked_select(labels, target_mask)\n",
    "        self.log(\"val_loss\", loss, on_step=True, prog_bar=True)\n",
    "        output = {\"outs\": out, \"labels\": labels}\n",
    "        return {\"val_loss\": loss, \"outs\": out, \"labels\": labels}\n",
    "\n",
    "    def validation_epoch_end(self, validation_ouput):\n",
    "        out = np.concatenate([i[\"outs\"].cpu().detach().numpy()\n",
    "                              for i in validation_ouput]).reshape(-1)\n",
    "        labels = np.concatenate([i[\"labels\"].cpu().detach().numpy()\n",
    "                                 for i in validation_ouput]).reshape(-1)\n",
    "        auc = roc_auc_score(labels, out)\n",
    "        self.print(\"val auc\", auc)\n",
    "        self.log(\"val_auc\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saint_plus = PlusSAINTModule()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(gpus=-1, max_epochs=5, progress_bar_refresh_rate=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model=saint_plus,\n",
    "            train_dataloader=train_loader,\n",
    "            val_dataloaders=[val_loader, ])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
